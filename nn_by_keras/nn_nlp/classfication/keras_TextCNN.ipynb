{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "#tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 0\n",
    "\n",
    "np.random.seed(seed_value)\n",
    "tf.set_random_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 data&feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.preprocessing.sequence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.TextLineDataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.Dataset.concatenate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.cardinality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_names = [[os.path.join('../data/aclImdb/train/pos/',i) for i in os.listdir('../data/aclImdb/train/pos/')]\n",
    "             ,[os.path.join('../data/aclImdb/train/neg/',i) for i in os.listdir('../data/aclImdb/train/neg/')]]\n",
    "test_file_names=[[os.path.join('../data/aclImdb/test/pos/',i) for i in os.listdir('../data/aclImdb/test/pos/')]\n",
    "             ,[os.path.join('../data/aclImdb/test/neg/',i) for i in os.listdir('../data/aclImdb/test/neg/')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_data = list()\n",
    "train_text_label = list()\n",
    "for i,j in enumerate(train_file_names):\n",
    "    label = 1-i%2\n",
    "    for file in j:\n",
    "        file_data = open(file,'r').read()\n",
    "        train_text_data.append(file_data)\n",
    "        train_text_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/aclImdb/train/pos/4715_9.txt'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_names[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_text_data = list()\n",
    "test_text_label = list()\n",
    "for i,j in enumerate(test_file_names):\n",
    "    label = 1-i%2\n",
    "    for file in j:\n",
    "        file_data = open(file,'r').read()\n",
    "        test_text_data.append(file_data)\n",
    "        test_text_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = list(zip(train_text_data,train_text_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"It took 9 years to complete this film. I would think that within those 9 years someone would have said,hey, this film is terrible. I've seen better acting in porn movies. The story is tired and played. Abused child turns into serial killer. How about something new for a change. How about abused child turns into a florist? At least that would have been a new twist. Why is it that everyone with a camera and a movie idea (especially unoriginal movie ideas) thinks that they can be a director? I do admire the fact that they stuck with this film for 9 years to get it completed. That shows tenacity and spirit. With this kind of drive hopefully next time they can focus it on a better script. If you want to see a failed experiment in indie film making from a writer/director from Michigan see Hatred of A Minute. If you want a good movie from a Michigan writer/director stick with Evil Dead.\",\n",
       "  0),\n",
       " (\"Stan & Ollie become SAPS AT SEA when their wayward little boat is commandeered by a vicious murderer.<br /><br />The Boys are wonderful in this feature, which starts out with one of their most hilarious set pieces, the horn factory. Always a few steps out of sync with the rest of Creation, Laurel & Hardy inhabit a world where icy radios & bedded billy goats are the rule, not the exception. With its brief length, the film is more in style with their classic short subjects, which explains its episodic nature.<br /><br />Only the Boys get screen credit, but movie mavens will recognize other familiar faces: James Finlayson appears as a loony doctor, Richard Cramer does full justice to his bad guy role, sweet Mary Gordon plays the Boys' perplexed neighbor. That's Charlie Hall as the apartment house desk clerk and silent screen comic Ben Turpin portrays a most peculiar plumber.<br /><br />One of the film's script writers was silent comedian Harry Langdon.<br /><br />Stan & Ollie are the main focus, however. Watching Hardy go berserk at the sound of a horn, or Laurel's antics with bananas, for instance, reminds the viewer why these fellows remain absolute cinematic giants.\",\n",
       "  1)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_data)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_eval = train_data[:int(np.array(train_data).shape[0]*0.2)]\n",
    "train_data_train = train_data[int(np.array(train_data).shape[0]*0.2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x = [i[0] for i in train_data_train]\n",
    "train_data_y = [i[1] for i in train_data_train]\n",
    "\n",
    "eval_data_x = [i[0] for i in train_data_eval]\n",
    "eval_data_y = [i[1] for i in train_data_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_y = test_text_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sisters in law will be released theatrically on march 24th in Sweden. A good occasion for our Nordic friends to discover this original and thoughtful documentary. It was shown in Göteborg together with a retrospective dedicated to Kim Longinotto, \"director in focus\" of the festival. She gave a master class, very much appreciated, telling about her method as documentary filmmaker and told the audience about the special circumstances which led her to shoot Sisters in law twice : the first version got lost for good, so a second shooting was organized and the film turned out to be different at the end. A pretty awful problem happened, in this case, to create the possibility of a very strong movie.',\n",
       " 'In a year of pretentious muck like \"Synecdoche, New York\" a film born out of Charlie Kaufman\\'s own self-indulgence, comes a film that is similarly hard to watch but about three times as important. \"Frownland\" is a labor of love by the crew, the actors and the filmmaker, shot over years by friends. It traces a man who cannot communicate through his thoroughly authentic, REAL Brooklyn world. The people that you see are a step beyond even the stylization of the \"mumblecore\" movement. They are real people, painfully trapped in their own self-contained neuroses, unwilling to change, unable. The real world to them is their own set of delusions and because this is a film about people who are so profoundly out of touch, it is very difficult to watch. It is 16mm film-making without proper light, money or any of the other factors that would make a film \"slick\", but its honesty can not be understated, a fact that would cause a room full of people to dismiss it and for Richard Linklater to give it an award as he did at SXSW. This does remind of films like \"Naked\" or the best of the \"mumblecore\". It is a film that is not for everyone, but one that challenges you to watch and grows on you the longer you think about it.']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_x[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"It took 9 years to complete this film. I would think that within those 9 years someone would have said,hey, this film is terrible. I've seen better acting in porn movies. The story is tired and played. Abused child turns into serial killer. How about something new for a change. How about abused child turns into a florist? At least that would have been a new twist. Why is it that everyone with a camera and a movie idea (especially unoriginal movie ideas) thinks that they can be a director? I do admire the fact that they stuck with this film for 9 years to get it completed. That shows tenacity and spirit. With this kind of drive hopefully next time they can focus it on a better script. If you want to see a failed experiment in indie film making from a writer/director from Michigan see Hatred of A Minute. If you want a good movie from a Michigan writer/director stick with Evil Dead.\",\n",
       " \"Stan & Ollie become SAPS AT SEA when their wayward little boat is commandeered by a vicious murderer.<br /><br />The Boys are wonderful in this feature, which starts out with one of their most hilarious set pieces, the horn factory. Always a few steps out of sync with the rest of Creation, Laurel & Hardy inhabit a world where icy radios & bedded billy goats are the rule, not the exception. With its brief length, the film is more in style with their classic short subjects, which explains its episodic nature.<br /><br />Only the Boys get screen credit, but movie mavens will recognize other familiar faces: James Finlayson appears as a loony doctor, Richard Cramer does full justice to his bad guy role, sweet Mary Gordon plays the Boys' perplexed neighbor. That's Charlie Hall as the apartment house desk clerk and silent screen comic Ben Turpin portrays a most peculiar plumber.<br /><br />One of the film's script writers was silent comedian Harry Langdon.<br /><br />Stan & Ollie are the main focus, however. Watching Hardy go berserk at the sound of a horn, or Laurel's antics with bananas, for instance, reminds the viewer why these fellows remain absolute cinematic giants.\"]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data_x[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 分词& padding example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.preprocessing.text.Tokenizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.preprocessing.text.Tokenizer.fit_on_sequences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = keras.preprocessing.text.Tokenizer(num_words=20000,oov_token=True,split=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "token.fit_on_texts(train_data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data_x = token.texts_to_sequences(train_data_x)\n",
    "eval_data_x = token.texts_to_sequences(eval_data_x)\n",
    "test_data_x = token.texts_to_sequences(test_text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "keras.preprocessing.sequence.pad_sequences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x = keras.preprocessing.sequence.pad_sequences(train_data_x,maxlen=MAX_LEN,padding='post')\n",
    "eval_data_x = keras.preprocessing.sequence.pad_sequences(eval_data_x,maxlen=MAX_LEN,padding='post')\n",
    "test_data_x = keras.preprocessing.sequence.pad_sequences(test_data_x,maxlen=MAX_LEN,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.Dataset.batch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.Dataset.shuffle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_data_x,train_data_y)).shuffle(buffer_size=20000).cache().batch(128)\n",
    "\n",
    "eval_ds = tf.data.Dataset.from_tensor_slices((eval_data_x,eval_data_y)).shuffle(buffer_size=5000).cache().batch(128)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_data_x,test_data_y)).shuffle(buffer_size=25000).cache().batch(256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "##input: batch_size max_len "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import  Input,Embedding,Dense,LSTM,Bidirectional,Conv1D,GlobalAvgPool1D,GlobalMaxPool1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "Embedding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv1D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "GlobalAvgPool1D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "GlobalMaxPool1D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = tf.keras.layers.Input(shape=(MAX_LEN,),name='input_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_x = tf.keras.layers.Embedding(input_dim=20000,output_dim=128)(input_x)\n",
    "embed_x = tf.keras.layers.Dropout(0.5)(embed_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Conv1D(filters=128,kernel_size=7,padding='valid',activation='relu',strides=3)(embed_x)\n",
    "x = tf.keras.layers.Conv1D(filters=128,kernel_size=7,padding='valid',activation='relu',strides=3)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.GlobalMaxPool1D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tf.keras.layers.Dense(units=1,activation='sigmoid',name='pred')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = tf.keras.models.Model(inputs=input_x, outputs=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_x (InputLayer)         [(None, 500)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_9 (Embedding)      (None, 500, 128)          2560000   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 165, 128)          114816    \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 53, 128)           114816    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "pred (Dense)                 (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,789,761\n",
      "Trainable params: 2,789,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn.compile(optimizer='adam',loss=keras.losses.binary_crossentropy)#,metrics=[keras.metrics.binary_accuracy,keras.metrics.binary_crossentropy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = nn.fit(x=train_data_x,y=train_data_y,validation_data=[eval_data_x,eval_data_y],epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(optimizer='adam',loss=tf.keras.losses.mean_squared_error,metrics=[tf.keras.metrics.binary_accuracy,tf.keras.metrics.binary_crossentropy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 157 steps, validate on 40 steps\n",
      "Epoch 1/3\n",
      "157/157 [==============================] - 514s 3s/step - loss: 0.1862 - binary_accuracy: 0.6858 - binary_crossentropy: 0.5435 - val_loss: 0.1053 - val_binary_accuracy: 0.8572 - val_binary_crossentropy: 0.3369\n",
      "Epoch 2/3\n",
      "157/157 [==============================] - 437s 3s/step - loss: 0.0768 - binary_accuracy: 0.8964 - binary_crossentropy: 0.2584 - val_loss: 0.0944 - val_binary_accuracy: 0.8788 - val_binary_crossentropy: 0.3180\n",
      "Epoch 3/3\n",
      "157/157 [==============================] - 447s 3s/step - loss: 0.0429 - binary_accuracy: 0.9462 - binary_crossentropy: 0.1611 - val_loss: 0.1062 - val_binary_accuracy: 0.8648 - val_binary_crossentropy: 0.3945\n"
     ]
    }
   ],
   "source": [
    "history = nn.fit(train_ds,epochs=3,validation_data=eval_ds)#,steps_per_epoch=int(20000/128),validation_steps=int(5000/128100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91/98 [==========================>...] - ETA: 9s - loss: 0.1096 - binary_accuracy: 0.8554 - binary_crossentropy: 0.3979 "
     ]
    }
   ],
   "source": [
    "nn.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
