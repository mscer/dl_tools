{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_src,y_train_src),(x_test_src,y_test_src) = mnist.load_data('./mnist.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_src.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train_src/255.\n",
    "x_test = x_test_src/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "num_class = len(set(y_train_src))\n",
    "print(num_class)\n",
    "print(set(y_train_src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ont_hot(y_train_src,num_class):\n",
    "    '''\n",
    "    not in-line process\n",
    "    '''\n",
    "    y_train = list()\n",
    "    y_train_copy = y_train_src.copy()\n",
    "    for i in range(y_train_copy.shape[0]):\n",
    "        index = y_train_copy[i]\n",
    "        row = np.zeros(num_class)\n",
    "        row[index] = 1\n",
    "        y_train.append(row)\n",
    "    y_train = np.array(y_train)\n",
    "    assert(y_train.shape[0] == y_train_src.shape[0])\n",
    "    return y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = ont_hot(y_train_src,num_class)\n",
    "y_test = ont_hot(y_test_src,num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000, 10)\n",
      "(10000, 28, 28) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 28\n"
     ]
    }
   ],
   "source": [
    "(m,n) = x_train.shape[1:];\n",
    "print(m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32,shape=[None,m,n])\n",
    "y = tf.placeholder(dtype=tf.int16,shape=[None,num_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_flag = tf.reshape?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_flat = tf.reshape(x,shape=[-1,m*n],name='flat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_connect(input_x,n_hidden,name,activation = None):\n",
    "    '''\n",
    "    name_score and name for get_variable\n",
    "    '''\n",
    "    with tf.name_scope(name):\n",
    "        i_dim = int(input_x.shape[1])\n",
    "        stddev = 2./np.sqrt(i_dim)\n",
    "        w = tf.Variable(tf.truncated_normal(shape=[i_dim,n_hidden],stddev=stddev),name='weight')\n",
    "        b = tf.Variable(tf.zeros([n_hidden]),dtype=tf.float32)\n",
    "        output = tf.matmul(input_x,w) + b\n",
    "        if activation == 'relu':\n",
    "            activ = tf.nn.relu(output)\n",
    "        elif activation == 'sigmoid':\n",
    "            activ = tf.nn.sigmoid(output)\n",
    "        elif activation == 'tanh':\n",
    "            activ = tf.nn.tanh(output)\n",
    "        else  :\n",
    "            activ = output\n",
    "        return activ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = 100\n",
    "hidden2 = 200\n",
    "output = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_1 = full_connect(x_flat,hidden1,'h1',activation='relu')## 换成sigmoid效果很差很多\n",
    "h_2 = full_connect(h_1,hidden2,'h2',activation='relu')\n",
    "output = full_connect(h_2,output,'output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.nn.softmax_cross_entropy_with_logits?\n",
    "#label可以是softmax分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.nn.sparse_softmax_cross_entropy_with_logits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_loss = tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=output,name='all_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None)])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_loss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(all_loss,name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize = tf.train.GradientDescentOptimizer(learning_rate=1e-2)\n",
    "train_op = optimize.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct = tf.nn.top_k?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = tf.reduce_mean(tf.cast(tf.equal(tf.nn.top_k(output,name='k1')[1], tf.nn.top_k(y,name='k2')[1]),float),name = 'acc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()## for save and restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saver.save?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batch(n_epochs,batch_index,batch_size,x_train,y_train):\n",
    "    beg = (batch_index -1)*batch_size\n",
    "    end = batch_index *batch_size\n",
    "    return x_train[beg:end],y_train[beg:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 6\n",
    "batch_size = 128\n",
    "num_batch = int(x_train.shape[0]/batch_size) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t100\t1.239328\t0.664062\t0.709800\n",
      "0\t200\t0.664090\t0.828125\t0.812900\n",
      "0\t300\t0.681339\t0.789062\t0.849900\n",
      "0\t400\t0.518813\t0.843750\t0.867100\n",
      "1\t100\t0.519469\t0.835938\t0.883000\n",
      "1\t200\t0.366485\t0.898438\t0.890200\n",
      "1\t300\t0.434423\t0.828125\t0.895500\n",
      "1\t400\t0.361221\t0.890625\t0.900300\n",
      "2\t100\t0.420835\t0.867188\t0.904000\n",
      "2\t200\t0.318010\t0.890625\t0.908500\n",
      "2\t300\t0.354090\t0.882812\t0.912200\n",
      "2\t400\t0.298957\t0.890625\t0.913700\n",
      "3\t100\t0.376177\t0.890625\t0.915600\n",
      "3\t200\t0.296010\t0.906250\t0.916400\n",
      "3\t300\t0.313614\t0.898438\t0.920000\n",
      "3\t400\t0.259571\t0.898438\t0.921100\n",
      "4\t100\t0.349147\t0.906250\t0.923000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    for i in range(num_epochs):\n",
    "        for j in range(1,num_batch):\n",
    "            sample_x,sample_y = fetch_batch(i,j,batch_size,x_train,y_train)\n",
    "            if j% 100 == 0:\n",
    "                acc_train,_ ,loss_val,= sess.run([acc,train_op,loss],feed_dict={x:sample_x,y:sample_y})\n",
    "                acc_test,= sess.run([acc],feed_dict={x:x_test,y:y_test})\n",
    "                print('%d\\t%d\\t%f\\t%f\\t%f'%(i,j,loss_val,acc_train,acc_test))\n",
    "            else:\n",
    "                sess.run([train_op],feed_dict={x:sample_x,y:sample_y})\n",
    "                \n",
    "    acc_train,loss_val = sess.run([acc,loss],feed_dict={x:x_train,y:y_train})\n",
    "    acc_test, = sess.run([acc],feed_dict={x:x_test,y:y_test})\n",
    "    \n",
    "    print('%f\\t%f\\t%f'%(loss_val,acc_train,acc_test))\n",
    "    saver.save(sess,'./model/mlp',global_step=i*j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saver.restore?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 eval test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'./model/mlp-2340')\n",
    "    accuary,loss_val,= sess.run([acc,loss],feed_dict={x:x_test,y:y_test})\n",
    "    print('%f\\t%f'%(loss_val,accuary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
